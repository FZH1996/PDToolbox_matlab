\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{float} 
\usepackage{ctable}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsfonts}
\usepackage{cite}
%\usepackage{algorithmic}
\usepackage[]{algorithm2e}

\usepackage{listings}
\lstset{breaklines=true} 


\def\th{^{th}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\pop}{\mathcal{P}}

\def\th{^{th}}
\def\pd{\frac{\partial}{\partial q_i^k}}
\newcommand{\mcf}[1]{p\Big( \norm{\bs{#1}^k}_1 \Big)}
\def\pdy{\frac{\partial}{\partial y_i^k}}
\def\pdq{\frac{\partial}{\partial q_i^k}}
\newcommand{\diag}{\mathop{\mathrm{diag}}}
%\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

\newcommand{\normb}[1]{\left\lVert \bs{#1} \right\rVert_1}


\usepackage{autonum}


\title{Population Dynamics Toolbox}
\author{Carlos Barreto}

\begin{document}

\maketitle



\begin{abstract}
 This is set of tools to implement evolutionary dynamics with multiple populations. We consider both small and large populations. For finite populations, we implement some revision protocols to model random interactions between agents. On the other hand, the evolution of a society with large populations is approximated by means of dynamical equations. 
 
 The toolbox is designed to facilitate the implementation of any game, as well as the implementation of different evolutionary dynamics and/or revision protocols.  In particular, our attempt is to make an efficient implementation of the algorithms to compute the dynamical evolution of the society. Also, the toolbox counts with some functions to plot the state of the system and the evolution of each strategy.
 
 
 
 
 
\end{abstract}


\tableofcontents



\section{Introduction}


% notation

Let us define a society of $\pop = \{ 1, \ldots, P\}$ composed by $P \geq 1$ populations. Each population consist of a large number of agents, which conform a mass $m^p > 0$, with $p \in \pop$. 
Let $S^p = \{ 1, \ldots, n^p \}$ be the set of actions (or pure strategies) available for each agent of the $p\th$ population. 
Each agent selects a pure strategy and the resulting state of the population is the usage proportion of each strategy. The set of population states is defined as $X^p = \{ x^p \in \mathbb{R}_+^{n^p} : \sum_{i \in S^p} x_i^p = m^p \}$, where the $i\th$ component of the state, denoted by $x_i^p \in \mathbb{R}_+$, is the mass of players that select the $i\th$ strategy of the population $p$.

Population games (or large games) capture some properties of the interactions of many economic agents:

\begin{enumerate}
\item large number of agents.
\item Continuity: The actions of an agent has small impact on the payoff of other agents.
\item Anonymity: means that the utility of each agent only depends on the aggregated actions of the other agents.
\end{enumerate}



In particular, an economic agent decides whether to modify or not its strategy according to the available information. In this respect, we assume that the agent's behavior satisfies both inertia and myopia properties. On the one hand, inertia 
is the tendency to remain at the status-quo, unless there exist motives to do that.
Also, this implies that the strategy adjustment events are rare events.
On the other hand, myopia means that the information used to make decisions is limited, e.g., each user makes decisions based on the current state of the population and do not estimate future actions. These two properties are based on the population games theoretical framework \cite{sandholm_book}
and behavioral economics \cite{gal}.

To accomplish the inertia property, the time between two successive updates of one 
agent's strategy is modeled with an exponential distribution (this distribution is used to model the occurrence of rare events). 
Thus, strategy actualization events could be characterized by means of stochastic alarm clocks.
Particularly, a rate $R_i$ Poisson alarm clock produces time among rings described by
a rate $R_i$ exponential distribution.
%These probabilities distributions are widely used by their memory-less property in stochastic analysis \cite{boyd, acemoglu2010, sandholm_book}. Thus, when all the agents of the population are provided with a rate $R_i$ Poisson alarm clock,
The whole actualization events in the population can be considered as a rate $R=\sum_{j\in \mathcal{V}} R_j$ Poisson alarm clock.
Therefore, the average number of events in a given time interval is $R$ and the probability of selecting the $i^{th}$
agent in a given time instant is
 $\frac{R_i}{R}$ \cite{sandholm_book}.

At each update opportunity (revision opportunity), the $i\th$ agent might compare the average profit of its strategy with the average profit of other strategies. Particularly, an agent might change its strategy with rate $\rho_{ij}$.
 
 The rate of change $\rho_{ij}$ is determined by a revision protocol, which defines the procedure used by each user to decide whether to change or not its strategy. The scalar $\rho_{ij} (\pi^p, x^p)$ is the \emph{conditional switch rate} from strategy $i$ to strategy $j$ in function of a given payoff vector $\pi$ and a population state $x^p$.
 
 Using the law of large numbers we can approximate the evolution of the society's state to a dynamical equation defined by
 \begin{equation}\label{eq:mean_dynamic}
  \dot{x}_i^p = \sum_{j\in S^p} x_j^p \rho_{ij} (\pi^p, x^p) - x_i^p \sum_{j\in S^p} \rho(\pi^p, x^p).
 \end{equation}
The previous equation is known as the \emph{mean dynamic}, which is used to define  some of the dynamics in the next section.

 
 
 \section{Revision Protocols and Evolutionary Dynamics}\label{sec:protocols}
 
 
In this section we introduce four revision protocols, that lead to the evolutionary dynamics \emph{logit dynamics} (Logit), \emph{replicator dynamics} (RD), \emph{Brown-von Neumann-Nash dynamics} (BNN), and \emph{Smith dynamics} (Smith). These dynamics belong to the families of \emph{perturbed optimization}, \emph{imitative dynamics}, \emph{excess payoff dynamics}, and \emph{pairwise comparison dynamics}, respectively \cite{hofbauer2001nash, sandholm_book}. 
 
 
 
 
 \subsection{Pairwise Proportional Imitation (Replicator Dynamics)}

The $i\th$ agent observes an opponent $j$ at random. Then it might change its strategy if  its opponent has a greater fitness. The rate change is 
%
\begin{equation}
\rho_{ij}^p(\pi^p, x^p) = \frac{1}{m^p} [\pi_j^p - \pi_i^p]_+
\end{equation}
%In this case, $x_j$ need not be observed. 
This protocol lead to the replicator dynamics defined as
\begin{equation}\label{eq:replicator}
\dot{x}_i^p = x_i^p \, \hat{F}_i^p \left( x \right),
\end{equation}
where $\hat{F}_i^p$ is the excess payoff to strategy $i\in S^p$, which is defined as   
\begin{equation}
\hat{F}_i^p (x) =  F_i^p(x) - \bar{F}^p(x),
\end{equation}
and $\bar{F}^p(x)$ is the average payoff the population $p$, i.e., 
\begin{equation}
 \bar{F}^p(x) = \frac{1}{m^p} \sum_{j \in S^p} x_j^p F_j^p(x).
\end{equation}



\subsection{Comparison to the Average Payoff (Brown-von Neumann-Nash Dynamics (BNN))}

The $i\th$ agent selects a strategy at random and might switch to it if that strategy has a payoff above the average. The agent switch strategy with probability proportional to the excess payoff
%
\begin{equation}
\rho_{ij}^p(\pi^p, x^p) = \left[ \pi_j^p - \frac{1}{m^p} \sum_{k\in S^p} x_k^p \pi_k^p \right]_+
\end{equation}

This protocol lead to BNN dynamics, defined as 
\begin{equation}\label{eq:bnn}
 \dot{x}_i^p = \left[ \hat{F}_i^p \left( \bs{x} \right) \right]_+ - x_i^p  \sum_{j \in S^p} \left[ \hat{F}_j^p \left( \bs{x} \right) \right]_+.
\end{equation}

\subsection{Pairwise Comparison (Smith Dynamics)}

The $i\th$ agent selects a strategy at random. If the opponent has a higher fitness, the the agent switch strategy with probability proportional to
\begin{equation}
\rho_{ij}(\pi, x) = \left[ \pi_j - \pi_i \right]_+
\end{equation}

This protocol leads to Smith dynamics that are defined as 
%
\begin{multline} 
\dot{x}_i^p  = \sum_{\gamma \in S^p} x_\gamma^p  \left[ F_i^p \left( \bs{x} \right) - F_\gamma^p \left( \bs{x} \right) \right]_+ 
%%\\
- x_i^p  \sum_{\gamma \in S^p} \left[ F_\gamma^p ( \bs{x}) - F_i^p( \bs{x} ) \right]_+.
\label{eq:smith}
\end{multline}



\subsection{Logit Choice}

The $i\th$ agent selects a strategy at random and change its strategy with a probability proportional to 

\begin{equation}
\rho_{ij}(\pi) = \frac{ \exp(\pi_j \eta^{-1} ) }{ \sum_{k \in S} \exp(\pi_k \eta^{-1} ) }
\end{equation}

This protocol belong to target dynamics and with a large population results in the following dynamics
\begin{equation}\label{eq:logit}
 \dot{x}_i^p = \frac{ \exp\left(\eta^{-1} F_i^p (\bs{x}) \right) }{ \sum_{\gamma \in S^p} \exp\left(\eta^{-1} F_\gamma^p (\bs{x}) \right) }, \, \, \eta>0,
\end{equation}
known ad Logit dynamics. 




\iffalse
\subsection{Maynard Smith Replicator}

\begin{equation}
\dot{x}_i = \frac{ x_i F_i }{ \bar{F}(x) } - x_i
\end{equation}
\fi




\subsection{Examples}



\begin{figure}[th]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_finite_proportional_imitation.eps}
	  \caption{Small population.}
	  \label{fig:finite1_protocol}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_rd.eps}
	  \caption{Large popultion.}
	  \label{fig:finite1_dynamics}
  \end{subfigure}
  \caption{Rock-paper-scissors game with a) proportional imitation revision protocol and b) replicator dynamics.}
  \label{fig:finite1}
\end{figure}


\begin{figure}[th]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_finite_comparison2average.eps}
	  \caption{Small population.}
	  \label{fig:finite2_protocol}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_bnn.eps}
	  \caption{Large popultion.}
	  \label{fig:finite2_dynamics}
  \end{subfigure}
  \caption{Rock-paper-scissors game with a) comparison to average revision protocol and b) BNN dynamics.}
  \label{fig:finite2}
\end{figure}


\begin{figure}[tbh]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_finite_pairwise_comparison.eps}
	  \caption{Small population.}
	  \label{fig:finite3_protocol}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_smith.eps}
	  \caption{Large popultion.}
	  \label{fig:finite3_dynamics}
  \end{subfigure}
  \caption{Rock-paper-scissors game with a) pairwise comparison revision protocol and b) Smith dynamics.}
  \label{fig:finite3}
\end{figure}


\begin{figure}[tbh]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_finite_logit_choice.eps}
	  \caption{Small population.}
	  \label{fig:finite4_protocol}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_logit.eps}
	  \caption{Large popultion.}
	  \label{fig:finite4_dynamics}
  \end{subfigure}
  \caption{Rock-paper-scissors game with a) logit choice revision protocol and b) Logit dynamics with $\eta=0.02$.}
  \label{fig:finite4}
\end{figure}





In this section, we implement rock-paper-scissors game with both revision protocols and evolutionary dynamics presented above, to observe the behavioral differences between a society with small number of agents and its approximation to a dynamical system.
The game has only one population with three strategies, denoted $x = [x_1, \, x_2, \, x_3]^\top$. The fitness function is defined as $F(x)=Ax$, where A is equal to 
\begin{equation}
  A = \begin{pmatrix}
  2  & 1 &  3 \\
  3  & 2 &  1 \\
  1 &  3 &  2
  \end{pmatrix}
\end{equation}
Note that we modify the payoff matrix proposed in the literature to ensure positive payoffs.
Fig. \ref{fig:finite1} to \ref{fig:finite4} show the evolution of the society with each revision protocol and its approximation to differential equations. We set the initial condition $x_0 = [0.2, \, 0.7, \, 0.1 ]^\top$. The small population cases are made with $200$ agents and $10000$ iterations. The dynamical cases are run during 
30 time units.


%The evolution might take place in days, months, years.

\input{implementation}












\section{Combined Dynamics}

It is possible to define a set of dynamics to run a combination of the dynamics. 
The resulting dynamic is defined as 
\begin{equation}
\dot{ x } = \sum_{d\in \mathcal{D}} \gamma_d V_d( x ),
\end{equation}
where $\mathcal{D}=\{ Logit, RD, Smith, BNN \}$ denotes the set of available dynamics, $V_d()$ is the differential equation of the $d\th$ dynamic and $\gamma_d$ is the weight assigned to it.
The dynamics should be defined in a cell array, e.g., 
\begin{lstlisting}
dynamics = {'bnn', 'rd'};
\end{lstlisting}
The combination is made making a linear combination between each dynamic listed in the cell array. The weight assigned to each dynamic is defined in the vector \verb|gamma|. In this case we assign 
\begin{lstlisting}
gamma = [.25, .75]; 
\end{lstlisting}

Fig. \ref{fig:rps_combined} shows an example of the combined dynamics for the rock-paper-scissors game. Note that the evolution of the system is not confined to a limit cycle, as happened with the replicator dynamics in Fig.  \ref{fig:finite1}.

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_combined.eps}
	  \caption{Simplex.}
	  \label{fig:test_combined_simplex}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test_combined_ev.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test_combined_ev}
  \end{subfigure}
  \caption{Evolution of the combination of replicator dynamics and BNN dynamics.}
  \label{fig:rps_combined}
\end{figure}









%\newpage

\section{Multi-population Games}



%\subsection{Examples}

\subsection{Matching pennies}

We implement a matching pennies game defining a society $\pop = \{p_1, p_2\}$ with two populations and two strategies per population, namely \emph{heads} and \emph{tails}. First, note that the payoff of the game in normal form is
%
\begin{table}[h]
\centering
 \begin{tabular}{|c|c|} \hline
  2, 1 & 1, 2 \\ \hline
  1, 2 & 2, 1 \\ \hline
 \end{tabular}
\end{table}
%
%In this case, the state of populations $1$ and $2$ are denoted by x^1 and x^2, respectively. .
Now, the fitness vector of the  population $p_j$ can be expressed as $F^{p_j}(x^{p_k}) = A^{p_j} x^{p_k}$, for $p_j, p_k \in \pop$ and $p_j \neq p_k$. That is, the payoff of a population is affected only by the state of the opponent population.
%$x^p \in $  $p=\{x_h^p, x_t^p\}$. 
The payoff matrices are defines as follows
%
\begin{equation}
  A^1 = \begin{pmatrix}
2 & 1 \\
1 & 2 
  \end{pmatrix}
\end{equation}
%
\begin{equation}
  A^2 = \begin{pmatrix}
  1 & 2 \\
  2 & 1 
  \end{pmatrix}
\end{equation}
%
Fig. \ref{fig:mp_game_rd} to \ref{fig:mp_game_logit} show the evolution of the social state with the evolutionary dynamics presented in Section \ref{sec:protocols}. 

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_simplex_rd.eps}
	  \caption{Simplex.}
	  \label{fig:test2_simplex_rd}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_ev_rd.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test2_ev_rd}
  \end{subfigure}
  \caption{Matching pennies game with replicator dynamics.}
  \label{fig:mp_game_rd}
\end{figure}



\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_simplex_maynard_rd.eps}
	  \caption{Simplex.}
	  \label{fig:test2_simplex_maynard_rd}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_ev_maynard_rd.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test2_ev_maynard_rd}
  \end{subfigure}
  \caption{Matching pennies game with Maynard replicator dynamics.}
  \label{fig:mp_game_maynard_rd}
\end{figure}



\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_simplex_bnn.eps}
	  \caption{Simplex.}
	  \label{fig:test2_simplex_bnn}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_ev_bnn.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test2_ev_bnn}
  \end{subfigure}
  \caption{Matching pennies game with BNN dynamics.}
  \label{fig:mp_game_bnn}
\end{figure}



\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_simplex_smith.eps}
	  \caption{Simplex.}
	  \label{fig:test2_simplex_smith}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_ev_smith.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test2_ev_smith}
  \end{subfigure}
  \caption{Matching pennies game with Smith dynamics.}
  \label{fig:mp_game_smith}
\end{figure}



\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_simplex_logit.eps}
	  \caption{Simplex.}
	  \label{fig:test2_simplex_logit}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test2_ev_logit.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test2_ev_logit}
  \end{subfigure}
  \caption{Matching pennies game with Logit dynamics with $\eta=0.02$.}
  \label{fig:mp_game_logit}
\end{figure}



\newpage
\subsection{Demand response programs}

This is an example of multiple populations used to implement demand response programs in smart grids. 
This example is based on \cite{barreto2013design, barreto2014incentives}.



We consider a population composed by $N$ consumers defined as $\mathcal{V} = {1,\ldots.N}$. Also, let us divide a period of 24 hours in a set of $T$ time intervals denoted $\tau = \{\tau_1,\ldots,\tau_T\}$.
Formally, we define the set $\tau$ as a partition of $[0,24)$, where 
 $\cup_{t\in\{1,\ldots,T\}} \tau_t = \tau$ and $\cap_{t\in\{1,\ldots,T\}} \tau_t = \varnothing$.
%
Let $q_i^t$ be the electricity consumption of the $i\th$ user in the $t\th$ time interval. 
The daily electricity consumption of the $i\th$ user is represented by the vector $\bs{q}_i=[q_i^1,\ldots,q_i^T]^\top\in \Re_{\geq 0}^{T}$.
The population consumption at a given time $t$ is defined by the vector $\bs{q}^t = [q_1^t,, q_2^t\ldots,q_N^t]^\top\in \Re_{\geq 0}^{N}$.
On the other hand, the joint electricity consumption of the whole population is denoted by $\bs{q} = [\bs{q}_1^\top,
\ldots, \bs{q}_N^\top]^\top$. 
Without loss of generality, we assume that the electricity consumption of the $i\th$ user  satisfies $q_i^t\geq 0$,  in each time instant $t$.
A \emph{valuation function} $v_i^t(q_i^t)$ models the \emph{valuation} that the $i\th$ user gives to an electricity consumption of $q_i^t$ units in the $t\th$ time interval. Finally, let $p(\cdot):\Re\rightarrow\Re$ be the price of electricity charged to consumers. The aggregated consumption at a given time $t$ is defined as $||\bs{q}^t||_1 = \sum_{j=1}^N q_j^t$.
Moreover, a daily valuation is 
$v_i(\bs{q}_i)=\sum_{t=1}^T v_i^t(q_i^t),$
 where $t\in\{1,\ldots,T\}$.


 
 
 
Now, assuming  that the electricity generation cost is  the same for all $t$, we can express the profit function of each individual as
%
\begin{equation}\label{eq:u_i_}
 U_i(\bs{q}) = v_i(\bs{q}_i) - \sum_{t=1}^T q_i^t p\Big( \norm{\bs{q}^t}_1 \Big),
\end{equation}
%
where 
$p:\Re_+ \to \Re_+$ is the unitary price function.
The consumers welfare function is maximized by solving \cite{Johari09}
%
\begin{equation}\label{eq:opt_problem}
\begin{aligned}
& \underset{\bs{q}}{\text{maximize}}
& &  \sum_{i=1}^N U_i(\bs{q}) =  \sum_{i=1}^N\left( v_i(\bs{q}_i) - \sum_{t=1}^T q_i^t p\left( \norm{\bs{q}^t}_1 \right) \right) \\
& \text{subject to}
& & q_i^t \geq 0,  i =\{1,\ldots,N\}, t =\{1,\ldots,T\}.
\end{aligned}
\end{equation}



\subsubsection{Incentives}

The solution of the optimization problem in Eq.~(\ref{eq:opt_problem}) is inefficient in a strategic environment, i.e., when individuals are rational and selfish \cite{barreto2013design, Johari09}. In such cases, the analysis of strategic interactions among rational agents is made using game theory \cite{fudenberg98}.
In particular, the Nash equilibrium (a solution concept in game theory)  is sub-optimal, however, we can show that if we consider an added incentive to the individual cost function of each player, the Nash equilibrium of the game with incentives can be made efficient in the sense of Pareto \cite{barreto2013design, barreto2014incentives}. 

In particular, our DR scheme with incentives models the case when all agents keep their valuation of electricity to themselves, and have autonomous control their consumption. However, in order to incentive the agents to modify their behavior for the good of the population, the central entity sends them an incentive (e.g., a price signal or reward) to indirectly control their load.

Consider the new cost function for the $i^{th}$ agent:
\begin{equation}\label{eq:game2}
W_i(q_i,\bs{q}_{-i}) 
%=  W_i(\bs{q}) + I_i(\bs{q}) 
= v_i(q_i) -  q_i p\left( \norm{\bs{q}^t}_1 \right) + I_i(\bs{q}) .
%\vspace{-.3cm}
\end{equation}
where incentives are of the form:
\begin{equation}\label{eq:I_i}
I_i(\bs{q}) = \left( \norm{\bs{q}_{-i}^t}_1\right) \left( h_i(\norm{\bs{q}_{-i}})  - p\left( \norm{\bs{q}^t}_1 \right) \right).
%\vspace{-.3cm}
\end{equation}


The form of this incentive is inspired in the 
Vickrey-Clarke-Groves mechanism and the  Clarke pivot rule \cite{AlgorithmicG}.
%
We assign incentives according to the contribution made by an agent 
to the society. In particular, the function $h_i:\Re \to \Re$ is a design parameter that estimates the externalities introduced by each individual.
%\begin{equation}\label{eq:h}
%h_i(\bs{\bs{q}}_{-i})=
%p\Big( \sum\nolimits_{j\neq i} q_j + f(\bs{\bs{q}}_{-i}) \Big),
%\end{equation}
%were $f(\cdot)$ might be a linear function. 
It can be shown that these incentives can lead to an optimal equilibrium in a strategic environment.
In this DR approach we consider that the utility sends a two dimensional signal to each customer, namely $(q,I_i)$ and each customer responds with some consumption $q_i$. 
Note that the incentives modify the price paid by each user according to their relative consumption. However, two different users receive different incentives as long as their consumption are different.


\iffalse

\section{Designing games}

In the previous section we show some examples of strategical situations that can be analyzed with game theory. In these cases, the structure of the game is given by the problem. However, we can modify the fitness function of each player in order to solve an optimization problem.

For example, let us consider the following optimization problem:

\begin{equation}\label{eq:opt_problem}
\begin{aligned}
& \underset{x}{\text{maximize}} 
& & \sum_{i=1}^N U_i(x_i)  - C(|x|)\\
& \text{subject to}
& & 0 \leq q_i \geq m,  i =\{1,\ldots, N\}.
\end{aligned}
\end{equation}

This can be seen as a problem of allocating a finite resource to maximize a utility function. 

Note that there are $N$ agents with that give a valuation $v_i(x_i)$ to the resource $x_i$.

However, the cost of assigning the resource is $C(|x|)$ .

The cost of assigning the resource might be distributed among the population. 

Let us consider the following example:


\begin{equation}
U_i(x_i) =   \alpha_i  log(1+x_i) 
\end{equation}

\begin{equation}
C(z) = \beta z^2 + b z 
\end{equation}

define fitness functions as 

\begin{equation}
f_i(x_1, x_2) = \frac{\alpha_i}{1+x_i} - 2 \beta |x| - b 
\end{equation}










------------

With a finite population the time specifies the number of iterations.

There might be different populations!!!

How do we define the state vector???




\fi












\bibliographystyle{plain}
\bibliography{references}




\iffalse


      
\begin{figure}[htb]
 \includegraphics[1\textwidth]{./images/}
 \caption{}
 \label{fig:}
\end{figure}




test1_ev_bnn.eps         test1_simplex_rd.eps     test2_simplex_bnn.eps
test1_ev_logit.eps       test1_simplex_smith.eps  test2_simplex_logit.eps
test1_ev_rd.eps          test2_ev_bnn.eps         test2_simplex_rd.eps
test1_ev_smith.eps       test2_ev_logit.eps       test2_simplex_smith.eps
test1_simplex_bnn.eps    test2_ev_rd.eps
test1_simplex_logit.eps  test2_ev_smith.eps
\fi

\end{document}










%\input{revision_protocols}

%\input{small_population}

%\input{evolutionary_dynamics}


\iffalse

\subsection{Examples}
We show examples of two games that have different number of populations and strategies per population.

\subsubsection{Rock-paper-scissors game}
We implement the rock-paper-scissors game. This game has only one population with three strategies, denoted $x = [x_1, x_2, x_3]^\top$. The fitness function is defined as $F(x)=Ax$.

Fig.\ref{fig:rpc_game_rd} to \ref{fig:rpc_game_logit} show the evolution of the social state. Note that the evolution of the dynamical approximation resembles the behavior of the system with small number of agents.


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_rd.eps}
	  \caption{Simplex.}
	  \label{fig:test1_simplex_rd}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_ev_rd.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test1_ev_rd}
  \end{subfigure}
  \caption{Rock-paper-scissors game with replicator dynamics.}
  \label{fig:rpc_game_rd}
\end{figure}


\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_bnn.eps}
	  \caption{Simplex.}
	  \label{fig:test1_simplex_bnn}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_ev_bnn.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test1_ev_bnn}
  \end{subfigure}
  \caption{Rock-paper-scissors game with BNN dynamics.}
  \label{fig:rpc_game_bnn}
\end{figure}



\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_smith.eps}
	  \caption{Simplex.}
	  \label{fig:test1_simplex_smith}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_ev_smith.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test1_ev_smith}
  \end{subfigure}
  \caption{Rock-paper-scissors game with Smith dynamics.}
  \label{fig:rpc_game_smith}
\end{figure}



\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_simplex_logit.eps}
	  \caption{Simplex.}
	  \label{fig:test1_simplex_logit}
  \end{subfigure}
  ~ 
  \begin{subfigure}[b]{0.45\textwidth}
	  \includegraphics[width=\textwidth]{./images/test1_ev_logit.eps}
	  \caption{Evolution of the strategies in time.}
	  \label{fig:test1_ev_logit}
  \end{subfigure}
  \caption{Rock-paper-scissors game with logit dynamics.}
  \label{fig:rpc_game_logit}
\end{figure}

\fi

